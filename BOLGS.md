# Name：Jin Yu
# Student number：21016015
# Github Link：
https://github.com/Jinaisrz/final_paper/blob/main/BOLGS.md
# Final Work video：
https://youtu.be/W3hGFIwyD0M
# Handshake Interaction Flow: 
https://youtu.be/s7owi1c-NfY
# Complete visualisation and operational procedures: 
https://youtu.be/s7owi1c-NfY


## Reference
### Project vision and basic technology reference, trianglesystem, particalsystem, discoverNeighbours, ColourGenerator:
https://openprocessing.org/sketch/1901346
### float effect: 
https://www.cssscript.com/infinite-float-effect-javascript-css3-floating-js/
### Bias point and bone binding principle:
https://editor.p5js.org/Sakura15/sketches/DByxkiHXi
### noStroke:
https://p5js.org/reference/#/p5/noStroke
### state:
https://editor.p5js.org/lmccart/sketches/rJGzVbn0l
### handpose:
https://editor.p5js.org/ima_ml/sketches/lrBwwxGiF

# Week 1: 7.10-7.16
My previous research explored the changes in Chinese strong ties culture in the context of the Internet and found that traditional strong ties were transformed into more multidimensional digital strong ties. In that week's research, I read a lot of literature, and in one of the studies, I pointed out that due to the emergence of the Internet, the traditional Chinese blood ties, geographic ties, karmic ties, and interest relationship have become digital strong ties, and that "interest relationship" are the most emerging and easier group to reach digital strong ties, and I used the interviews with members of gaming and fan circles to deduce and prove a model for the formation of digital strong ties. We reasoned and proved the formation model of digital strong ties, and found that digital strong ties has wider coverage and lower maintenance cost than traditional strong ties.

<img width="1050" alt="1" src="https://github.com/Jinaisrz/final_paper/assets/115119995/4e5ed5e8-ed6e-4972-bbfe-d1c7e16fc7a0">
<img width="1015" alt="2" src="https://github.com/Jinaisrz/final_paper/assets/115119995/93760580-4b5d-43ad-bf77-b0660e89c6fa">

# Week 2: 7.17-7.23
In that week, I analyzed Dr. Yanjie Bian's definition of traditional strong ties, the process of upgrading weak ties into digital strong ties, and the initial and stable phases of trust building in digital strong ties, and found that trust is like a kind of "social currency" that circulates multidimensionally in individual and group strong ties, because people have to build up enough trust in order to establish digital strong ties in any circumstances, and this kind of digital strong ties must have been born from long-time interactions with multidimensional interactions in the digital platform.

# Week 3: 7.24-7.30
Since trust is like a kind of "social currency", I try to analyze how trust circulates as a kind of currency in digital strong ties in a multi-dimensional way. Through reading the literature and analyzing the traditional strong ties and digital strong ties, I found that the core difference between them lies in the starting point of forming relationship - digital technology, because digital technology and platform are the foundation of the development of digital strong ties, and then rise to the establishment of person-to-person and person-to-group digital strong ties. Therefore, I define the direction of the circulation of trust as "trust-digital technologies and platforms-individuals-groups-results", but the details of the circulation need to be considered in this process.
<img width="727" alt="3" src="https://github.com/Jinaisrz/final_paper/assets/115119995/2ba4a90e-fc3a-4751-a792-80031d00708d">

# Week 4:7.31-8.6
I think out the direction of the circulation of trust based on last week: trust-digital technologies and platforms-individuals-groups-results, and I try to build a model of the circulation of trust in strong digital ties. Taking trust as the center to disperse outward to the first level - digital technology and platform layer, I read the literature and look back to the previous interviews, and finally found that trust is firstly built up by the reputation of the platform to a certain extent, and the user's interest and interaction with some people in it will be recorded by the data, so as to recommend the corresponding community, and thus may be better able to reach the digital strong ties. In my exploration of other social platforms digital platforms also quantify trust in multiple ways, e.g., in QQ, the two interacting parties automatically set a friendship level by the number of days the chat lasts each day, and when the interaction is interrupted for more than 3 days it is downgraded, which uses the frequency of people's interactions as a way to quantify trust.
![4](https://github.com/Jinaisrz/final_paper/assets/115119995/03de8869-cb5c-44a8-b684-5fceac42df68)

In my personal level exploration, I find that people building digital identities in a more authentic, complete, coherent, and sincere way in a secure platform leads to more stable personal trust, deep self-disclosure, and strengthened trust and digitally strong ties with others. From this I find that trust has quantifiable characteristics.

# Week 5: 8.7-8.13
I encountered a lot of difficulties in that week's research, especially in the research on the group level, I have studied a lot of literature on virtual communities, digital identity of groups and other directions, and found that the topic could not be further deepened. So I found a typical "interest relationship" individual around me, and through interviewing her, I found that as fans of celebrities, they are given many digital socialization methods by the platform in their own digital strong ties, and they are also differentiated into obvious grades in the group through the interaction design of the platform, and the higher the grade, the higher the degree of trust they have and the corresponding benefits they will get. The higher the rank, the more trusted they are and the more benefits they receive, and this hierarchy of trust leads to a more orderly digital strong ties community. The rich interaction methods within the community developed by the digital platform will also increase the digital strong ties among the members, such as completing the system tasks together, which will increase the two-way trust and thus better shape the collective identity and culture.
Through Week 4 and Week 5, I found that trust circulates in digital strong ties in ways that can be quantified, facilitate deep socialization over time, the maintenance and shaping of group values, and extend digital strong ties.

# Week 6: 8.14-8.20
The difficult point of the week's research is to dig deeper into the critical direction of the topic, digging over the direction of the entanglement in the digital strong ties of trust fraud, digital strong ties of the causes of instability of social trust, the virtual true and false, whether the trust is fragmented, the digital strong ties of the group polarization, etc., the week has been constantly going to look for breakthroughs, the readings of more than 50 papers.

# Week 7: 8.21-8.27
That week I refreshed all the existing papers to make all the textual content more concise so as to try to find a point of strength for the paper, and eventually realized that all the directions I took last week would make the context incoherent. I looked at all the analytics and found that the trust built in the context of digitally strong ties with interesting people is collected and pushed by algorithmic preferences and built by multiple interaction design mechanisms, which is why I questioned, is the trust built in the context of digitally strong ties pure? Is it all about "free will"? So I started with a simple analysis of the algorithmic guidance of trust and the intervention of interaction design mechanisms, and found that algorithms and recommender systems are constantly guiding the direction of individual social groups based on individual interests and behaviors, and through reading papers, I found that the quantization of trust will turn what should be a rich and colorful trust into a single one-sided tendency of trust hierarchy.

# Week 8: 8.28-9.3
In that week, I analyzed last week's research and read the paper, and found that the platform as the soil for the development of strong digital ties exploits the trust of the digital strong ties of "interest relationship", and I firstly found some practical examples that can prove this speculation, and found that trust is also used for the development of digital platforms and user adhesion, which in fact strengthens the relationship between people and the digital platforms. strong digital ties with digital platforms. In other studies, it has been pointed out that platform capitalism and algorithms change the structure of trust, transforming trust ties into trust capital, which appears to be the result of autonomous decision-making brought about by people's "free will", but is essentially the result of the platform capital's purposeful steering using smart algorithms.

# Week 9: 9.4-9.10
During the week I searched for papers on the platform's trust capital, free will, and the economy of "interest relationship" to support the theory and enrich the overall content and structure of the paper, and to come up with an analysis of all of last week's content, ultimately reflecting on the blurring of the boundaries of people's freedom of trust and the loss of sovereignty over their trust, and reflecting on their perspectives.

# Week 10: 9.11-9.17
During that week, I streamlined any lengthy or unnecessary content in the paper and then summarized the research. Then, I combed through all the cited literature in the research and labeled it with its proper serial number and reordered the article titles of the existing paper.

# Week 11: 9.18-9.24
Based on my research in the previous weeks, I thought about the scenarios and I looked at a range of computer artists such as: Rafael Lozano-Hemmer's "The Listening Post" by Mark Hansen and Ben Rubin - a dynamic art installation that collects and broadcasts text from internet chat rooms in real time. Jenny Holzer's LED installations - Jenny Holzer uses scrolling LED text to convey information, thoughts and social commentary. "Processing" by Casey Reas and Ben Fry. Kyle McDonald's "Social Soul," an immersive, interactive installation that allows users to experience the social media lives of others, and Golan Levin, a new media artist and engineer who often explores the interactions between humans and machines. His works such as "Double-Taker (Snout)" use computer vision and robotics to mimic human social behaviour.

After looking at the artist references, I started thinking about project ideas.

People to "call" behaviour in front of the screen receiver speaker to send their preferences for interaction, the system will automatically match a community point, the more people interact with the community in front of the screen, the coarser the strength of the relationship, next to the interaction to achieve the trust index, and in the strength of the relationship with the algorithm inside! visual elements such as vision, delivery of interactive content, and empathy. But when people stop interacting, the system allows the strength to diminish and people are in a passive interaction process, which is used to satirise the impact of the system on people's "trust" building, until finally the screen plays a film on the evolution of the trust structure of the digital strong ties to make a viewpoint.
![5](https://github.com/Jinaisrz/final_paper/assets/115119995/a1adecba-22dc-47cb-a62d-9e47949b1d17)

# Week 12: 9.25-10.1
Unsatisfied with the first scenario, I rethought a new one and settled on one that was more related to human "trust" behaviour.

I create a social platform, the audience can experience the project from the user's perspective. This plan is inspired by people's the most typical trust behaviour-- the "handshake".

### Experience the process:

1. When the audience uses my social platform, they first need to enter their username, and their interest direction.

2. After the audience enters the platform, they will first see a simple social network of hand (the bone points of the hand is the friends' data points, and on the data point, there will be the friends'  interest direction, the trust level, the messages, emoji, and so on) The audience will strengthen the frequency of interaction by shaking hand with each time. The beginning of the handshake also gradually recommends you choose the interest group.

3. When the user's interaction frequency and interaction trust level reaches a hight level, the system will change, from the original people actively choose with whom to shake hands, into the system to help you choose with whom to shake hands (for example: the player in front of the different trust level users, one of them is a high-level user with a title, the player with whom to shake hands, the system will automatically reject, and display 'your trust level is not enough, you have been given'), thus making irony.

### Experience the process:
Hand movements are captured through leap motion LM010 capture, and I'll use processing to write the visuals and interactions.
<img width="359" alt="6" src="https://github.com/Jinaisrz/final_paper/assets/115119995/08dac55f-8be9-4b9e-803a-dbe73ea54ad3">

### Visual reference, Hand social network structure and Hand Angle:
<img width="1121" alt="7" src="https://github.com/Jinaisrz/final_paper/assets/115119995/aae995ce-a3db-4d5c-a3e7-a1fc8dd1901d">

### Main Visual Design
<img width="1293" alt="8" src="https://github.com/Jinaisrz/final_paper/assets/115119995/3e4d8443-b8f4-4c15-a564-ecd39d34a297">

# Week 13: 10.2-10.8
## Tutor feedback
<img width="936" alt="feedback1" src="https://github.com/Jinaisrz/final_paper/assets/115119995/51e04797-217e-4910-b2b4-bad6bd39f471">

Much of Marysia's feedback came from the social research portion of the dissertation, which required sorting out the dissertation format, haver citing references. And go ahead and develop a technical prototype if possible.

## Cancell leapmotion & Processing plan
### Problems:
1. Thresholding and edge detection process the hand image to make the pixel sense too strong.
2. Fingers will not be recognised due to the dimming of the light, making the test results even worse.
3. Hand recognition generates a large number of pixels that make the image loading too slow.
<img width="1018" alt="9" src="https://github.com/Jinaisrz/final_paper/assets/115119995/efde23f6-e1e4-4ae2-a76d-f9c7c9f3aabc">
<img width="873" alt="10" src="https://github.com/Jinaisrz/final_paper/assets/115119995/0a7e222e-ecc5-4b05-9d62-f1ccb1f52935">

4. Difficult to see hand outline
<img width="1027" alt="11" src="https://github.com/Jinaisrz/final_paper/assets/115119995/12e31ac5-7f53-4135-988c-cad2656fb222">

# Week 14: 10.9-10.15
## Tutor feedback
<img width="928" alt="feedback2" src="https://github.com/Jinaisrz/final_paper/assets/115119995/39dd6cb6-7308-4b74-9957-cfc120b3f66d">

The main tip from the mentor feedback is to avoid really storing personal information such as the player's face, email address, etc. as much as possible, which may involve some unnecessary privacy risks, and feel free to store usernames, passwords, and other data.

## I use P5.js and the computer's camera to recognise my hand
I begin by first iterating through each prediction in the predictions array via the drawKeypoints function. Each keypoint contains its x, y coordinates on the image and a confidence score. For each prediction, it iterates through the array of keypoints. It then draws a circle for each keypoint and uses the line() function to connect each keypoint in order. This function can also contain other ways and logic to handle gesture recognition and interface feedback.

<img width="1022" alt="截屏2023-11-21 17 53 44" src="https://github.com/Jinaisrz/final_paper/assets/115119995/8d54bce0-28c6-401e-87ad-61d28361a919">

<img width="1200" alt="截屏2023-11-21 17 47 50" src="https://github.com/Jinaisrz/final_paper/assets/115119995/1b75b6bc-cf46-4356-bfcb-31fdb5944ef9">

### The reference of hand model:
https://editor.p5js.org/ima_ml/sketches/lrBwwxGiF

I found a reference where the particles and interconnecting lines can represent user points and social networks.
![13](https://github.com/Jinaisrz/final_paper/assets/115119995/31b2260d-20b9-4133-8e37-67b754923934)

### Reference:
[https://editor.p5js.org/ima_ml/sketches/lrBwwxGiF](https://openprocessing.org/sketch/1901346)https://openprocessing.org/sketch/1901346

## How are particles generated and how are particles connected to each other into visual social networks?
### Theory of Particle Neighbour Technology
I initialise an empty neighbours array to store the neighbours of the current particle by traversing the particles array in the ParticleSystem class, add the current particle itself to the neighbours array, and by this traversing through all the other particles and calculating their distance from the current particle. If another particle has a distance between MIN_TRI_DISTANCE and MAX_TRI_DISTANCE from the current particle, it is considered a neighbour and is added to the neighbours array.
Check the length of the neighbours array. If the length is within a specific range (greater than 1 and less than MAX_PARTICLE_NEIGHBOURS), I'm using the -40 to 40 determination distance here, and the condition is met, the addTriangles method of TriangleSystem is called and the neighbours array is passed as an argument.

<img width="902" alt="截屏2023-11-22 15 57 09" src="https://github.com/Jinaisrz/final_paper/assets/115119995/5993bba6-3c5d-41d9-bd03-b52ecc69421e">

A collection of triangles is then managed through the TriangleSystem class. The addTriangles method takes an array of particle neighbours, and first checks the length of the input array to make sure there are enough particles to form a triangle. A nested loop is used to iterate through the particles in the array of neighbours. For each particle, select two other particles to form a triangle. For each group of three particles, create a Triangle object that uses the positions of the three particles as the vertices of the triangle.

<img width="440" alt="截屏2023-11-22 18 25 07" src="https://github.com/Jinaisrz/final_paper/assets/115119995/5ba8b247-495e-483d-8f6f-96d81277dd5e">

Adds the newly created Triangle object to the ArrayList<Triangle> collection maintained by the TriangleSystem, resulting in a triangle.

<img width="700" alt="截屏2023-11-22 18 20 57" src="https://github.com/Jinaisrz/final_paper/assets/115119995/b4c25a01-2756-44c4-b25a-c43786d49834">

<img width="421" alt="截屏2023-11-22 15 55 52" src="https://github.com/Jinaisrz/final_paper/assets/115119995/918c501b-62da-4b7b-9597-42bab3e17044">

## How do particles and triangles follow the movement?
I first used ml5.js to get the coordinates of the key points of the hand. These coordinates represent the different points of the hand's bones. Then, the GetPoints class generates a random point on the line (joint vector) between these bone points, which is the position of the particle. In the ParticleSystem class, the update method is responsible for updating the position of these particles based on the movement of the hand. This means that the particles will move with the hand movement. Meanwhile, the discoverNeighbours method is used in ParticleSystem to identify particles that are close to each other. This method determines if the particles are close enough to form a triangle based on the distance between them.

Once neighbouring particles are identified, the addTriangles method of the TriangleSystem class is called. This method takes a set of neighbouring particles and uses them to create triangles. Each triangle consists of the positions of three particles as vertices.

Finally, as the particle positions are updated, the triangles created by the addTriangles method dynamically change accordingly. The result is a dynamic visual effect that changes with the movement of the hand, where the particles are constantly moving and rearranging, and the triangles are reconstructed and rendered accordingly.

<img width="1049" alt="17" src="https://github.com/Jinaisrz/final_paper/assets/115119995/3f5571a1-0e5f-4f67-ab6f-214e9ccd51f1">

<img width="316" alt="21" src="https://github.com/Jinaisrz/final_paper/assets/115119995/9f9e0c28-d09a-48bd-b20a-2251eaad1c9a">

# Week 14: 10.16-10.22
## Mean square error to determine the handshake and thus the colour change
### Mean square error handshake judgement
With my drawKeypoints function, the program uses the gesture recognition feature to detect hand poses. This procedure I started by traversing the predictions array, which contains the data for each hand recognised by the handpose model. For each hand's predictions, the program traverses all of its keypoints, draws those points, and calculates their mean square error with respect to the hand's centroid.

<img width="460" alt="24" src="https://github.com/Jinaisrz/final_paper/assets/115119995/796666a5-fbf3-4f32-9c0a-96b9a2f3d1fb">

This mean square error is obtained by calculating the sum of the squares of the distances from each keypoint to the centre point and dividing by the total number of keypoints. Based on the value of the mean square error, the program determines whether the hand is in a fisted state or not: if the mean square error is less than 6000 and the current isFist state is false, it is assumed that the hand is in a fisted state, and isFist is set to true, and the system.addParticle method is called to add particles in order to indicate that a fisted action is detected. Conversely, if the mean square error is greater than 6000, set isFist to false to indicate that the hand is not in a fist grip.

<img width="566" alt="25" src="https://github.com/Jinaisrz/final_paper/assets/115119995/d88271b8-ac09-479b-ba1a-e5086fef61c9">

### Resulting image of the mean square error handshake judgement
<img width="857" alt="23" src="https://github.com/Jinaisrz/final_paper/assets/115119995/b5737ada-0895-4c83-8acf-d6a7ff5362ae">

# Week 15: 10.23-10.29
## Cancell process: Mean Squared Error (MSE) for determining the "handshake" behaviour
As I cancelled this week, the logic for detecting handshakes and increasing the number of particles and triangles relies heavily on calculating the Mean Squared Error (MSE) at key points on the hand. Mean square error is a measure used to quantify the difference between sets of values. Here, it is used to determine the distance between the key points of the hand to recognise whether a handshake has occurred. When the hand is open, the 20 key points are more spread out. Conversely, during a handshake gesture, these 20 key points are closer to each other, resulting in an MSE value of less than 6000. therefore, when the MSE value is below this threshold, the handshake gesture can be determined to be complete.

But this way to let the device run too much pressure, so I only by judging the handshake when each finger's vertex changes to determine whether the completion of the handshake behaviour, I first made a flowchart to facilitate the understanding of my later code, the thumb's red vertex of the y-value relative to the green vertices of all the other fingers of the y-value the smaller, on behalf of the hand posture has been adjusted to the horizontal, when the 4 green vertices of the x-value is less than the value of the red vertices indicate that the hand pointing to the palm of the hand closer to the handshake has been put out of the posture.

So I start by making a judgement on isFist==true in code, and when the condition is met I simply have to have a judgement on how far up and down the thumb moves. So I recorded 10 thumb y-value movements by using thumbHistory, and when thumbDiff > 50, it was judged as a handshake.

<img width="1384" alt="截屏2023-11-21 21 36 20" src="https://github.com/Jinaisrz/final_paper/assets/115119995/f8dc3178-d478-46c0-ad93-7ef94a2f5b30">

<img width="480" alt="截屏2023-11-22 19 10 22" src="https://github.com/Jinaisrz/final_paper/assets/115119995/bb83d9b2-ee86-49bb-86f6-fafc119fd5db">

<img width="462" alt="截屏2023-11-22 19 10 46" src="https://github.com/Jinaisrz/final_paper/assets/115119995/35052477-5f7e-4356-8cfb-5ca8259883b9">

<img width="355" alt="截屏2023-11-22 19 17 14" src="https://github.com/Jinaisrz/final_paper/assets/115119995/c46264b9-3dc6-43da-947f-261998a6f0e9">

## Particles can't disappear, they need to keep growing
<img width="470" alt="22" src="https://github.com/Jinaisrz/final_paper/assets/115119995/75b74041-3c09-4ef0-8cba-b501352a089f">

The differentiation is initialising lifespan, updating lifespan and checking if the particle is "dead", in which every time the move method is called, the lifespan value will be decreasing because of the code this.lifespan -= LIFESPAN_DECREMENT; and this is contrary to the concept of a continuously growing number of users. constantly decreasing, so that the particles have the phenomenon of death, and this is contrary to the concept of continuous growth of the number of users, so you need to this.lifespan -= LIFESPAN_DECREMENT commented out, so that the lifespan value is never less than 0, you can let the number of particles to continue to grow, the particles will be due to addTriangles constantly increasing the number of triangles.

<img width="864" alt="19" src="https://github.com/Jinaisrz/final_paper/assets/115119995/b2c98f8b-b20e-4a83-ac2e-c5698f934cc4">

### Grip frequency affects colour change (for trust level design of colours)
By drawing the front line of the triangle in the display of addTriangles, draw the border of the triangle to 0, and call ColourGenerator to set R,G,B and call fill at the same time, and set the fill intensity of the triangle to a lower level by the following.

fill(amplify(processColor[0]), amplify(processColor[1]), amplify(processColor[2]), 30);

In this way the change in colour shade of a triangle is actually a change in colour shade formed by whether or not multiple triangles overlap, e.g. the particles are generated with the hand's as the vector, and no matter how the hand moves, the position of the particles with respect to the vector is always relatively unchanged, and so a triangle generated from the same three points will be darker in colour, whereas one alone will be lighter in colour.

The number of hand shakes is calculated by fistCount, which is linked to the trust level colour change value at the bottom of the screen in a colour process that sucks in pixel colours from left to right and fills them into the triangles to create the final colour change.

<img width="559" alt="截屏2023-11-22 16 02 53" src="https://github.com/Jinaisrz/final_paper/assets/115119995/57e4f38d-63a4-4522-90d2-9f886ecaac91">

<img width="954" alt="截屏2023-11-22 16 01 56" src="https://github.com/Jinaisrz/final_paper/assets/115119995/7442531b-c00c-4dac-8599-c2265f8fa07d">

# Week 16: 10.30-11.5
## Mean square error handshake to select images for home page interest groups

### Defining option points (checkpoints)：
There are three checkpoints defined in the checkChosen() function, which are located at specific locations on the canvas.

<img width="473" alt="32" src="https://github.com/Jinaisrz/final_paper/assets/115119995/f049ba8b-e86d-4440-9910-dd8be5029643">

### Detects the position of the hand:
The palm position is calculated in the drawKeypoints() function, the exact line number may vary depending on the rest of the code, which focuses on calculating the centre point of the bounding box.

<img width="238" alt="33" src="https://github.com/Jinaisrz/final_paper/assets/115119995/f134b82a-7bd2-4e03-9290-7b869ab1425a">

### Determines how close the palm position is to the option point:
This part is also in the checkChosen() function, which determines proximity by comparing the distance between the palm position and a predefined checkpoint:

<img width="465" alt="34" src="https://github.com/Jinaisrz/final_paper/assets/115119995/2077f695-cb7e-41e3-a973-cdb666e3c644">

### Select processing:
The code updates the state1 variable when it detects that the palm is close to one of the checkpoints and is in the fist state. This is also in the checkChosen() function.

<img width="221" alt="35" src="https://github.com/Jinaisrz/final_paper/assets/115119995/72328afe-b4e5-4362-a92b-1c6c360b32c3">

### Results:
The error in selecting interest groups by hand recognition is very large because the control of the coordinates is problematic and can lead to trying to accurately select one while the other is also selected.

<img width="1042" alt="29" src="https://github.com/Jinaisrz/final_paper/assets/115119995/f7bdafe1-5fa2-4216-b861-4fc774c35d54">

## Change to Mouse Selection
Since using the mean square error to interpret the coordinates of the selected interest group was too large and poorly controlled, I chose to select them via the mouse.

<img width="555" alt="30" src="https://github.com/Jinaisrz/final_paper/assets/115119995/8a15070a-ab2c-4810-a1c2-dc1240c9e1d7">

## emoji选择
I assign each particle a different emoji based on the value of tempChosen through the constructor of the Particle class.This logic is reflected in how the emoji assigned to the particle are determined based on the user's chosen interest group (e.g., Cristiano Ronaldo, Emma Watson, Elon Musk).Then in the display method, you can display these emoji on each particle so that one of each particle contains an emoji, creating a dynamic pattern of emoji on the screen.

<img width="745" alt="截屏2023-11-22 19 46 50" src="https://github.com/Jinaisrz/final_paper/assets/115119995/b7791bc6-b537-457b-9fc7-82b8ca2996f8">

<img width="1283" alt="emoji-1" src="https://github.com/Jinaisrz/final_paper/assets/115119995/860cbb53-c9a6-499e-b602-8e2dd2db4d89">

<img width="1284" alt="emoji-2" src="https://github.com/Jinaisrz/final_paper/assets/115119995/2c5b273a-ddf3-4eb7-a14e-bacadb36f3ca">

![女明星](https://github.com/Jinaisrz/final_paper/assets/115119995/6cec624b-3606-4534-88ca-85e31a6d535d)

![埃隆马斯克](https://github.com/Jinaisrz/final_paper/assets/115119995/f53d7c77-c0e9-4a25-8827-dd05276952b1)

Adjust the emoji to produce periodic changes through angle, at each particle update. Then by setting floatEffect to use sin(this.angle) to generate periodic fluctuation in value to simulate a floating effect, and then by using breathEffect, change the size or transparency of the emoji to add a breathing effect to the emoji. The final display is in the display method.

<img width="881" alt="emoji效果的手" src="https://github.com/Jinaisrz/final_paper/assets/115119995/08a344ec-0d69-4c1f-b61b-4a66fd87531c">

# Week 17:  11.6-11.13
This week we focus on how to have two hands on two screens at the same time, firstly by setting up two systems (system and system1) and other variables, and through the function drawKeypoints function, which is used to process and display the keypoints of the two hands, and then we need to iterate through all the landmarks of that hand, and the keypoint is the current traversed keypoint of one of the hands, and the keypoint1 is the previous keypoint, see the code below:

const keypoint = prediction.landmarks[j]; 
const keypoint1 = prediction.landmarks[j-1];

Then translate() is used to change and modulate the coordinate system of the two hands respectively, so that the dynamics of the two hands can be rendered independently on the same canvas, and the outline of the hand can be formed by setting the line style and drawing a line between the current keypoint and the previous keypoint according to the position of the applied state1 and keypoint.

<img width="1200" alt="截屏2023-11-19 19 26 01" src="https://github.com/Jinaisrz/final_paper/assets/115119995/16085a7a-272b-4f2e-b21d-4d8860ded979">

Then in order for the hand to display particles and triangles, I completed the duplication of the already complete particle system and triangle system by using system1.particles=system.particles and triangles1.triangles=triangles.triangles; and the relocation of the particle system also represents the The relocation of particles, triangles, colours, and emoji, but there was a bug in the implementation, which was clearly determined by the neighbourhood technique that the link between the two fingers would not be connected because the particles were too far away.

![WechatIMG201](https://github.com/Jinaisrz/final_paper/assets/115119995/13c46155-13a1-4893-80da-576754a2a9d0)

Eventually I found out by looking at it that my future two hand's in the screen would be over the option area, controlling the range of motion, here is the relevant code：

if(state1!=2||(transX(keypoint[0])>950&&transY(keypoint[1])>43&&transY(keypoint[1])<593))
if(transX(keypoint[0])>107+width/2&&transX(keypoint[0])<950+width/2)

At the same time, it is necessary to control the generation of particles, and use slice(0, system.articles.length/3) to reserve the first third of the particle reserve to control the total number.

It's a neighbourhood tech judgement that's also got a limit, for the overall effect so I've turned it off.

<img width="1198" alt="截屏2023-11-22 20 17 50" src="https://github.com/Jinaisrz/final_paper/assets/115119995/59f45a8a-f9a7-48cc-8ff0-c0d224cc90ad">

# Week 18: 11.14-11.21
## Selection of potentials and loss of control
I trigger the appropriate interaction effect by monitoring the hand position and determining whether a handshake has occurred, by tracking the position of the hand in real time using the handposition monitoring handp method to determine whether the hand has entered one of the two predetermined areas, A or B. Then, by using the handshake detection (isFist) to determine
If B is selected (boom is false), the application maintains the current state until the user selects A. This logic allows the user to select and switch between the different options through gestures and play the pre-set mp3 runaway audio, while B remains unchanged. Finally the tipText array is used to store all the text messages that will be displayed on the screen. By incrementally increasing the value of the yPos variable, you can scroll these text messages vertically on the screen. The for loop in the draw function uses yPos to determine which text messages are currently displayed. As yPos increases, different text messages are displayed, creating a continuous scrolling effect on the screen. Once yPos reaches a certain value, it resets to the initial value, creating a circular effect of scrolling text.

## Changes to the thesis with tutor
<img width="1026" alt="截屏2023-11-22 20 39 35" src="https://github.com/Jinaisrz/final_paper/assets/115119995/8759b341-f029-4908-a977-4ed1e4a06fdb">
According to the teacher prompted the content of basically all the changes, but the teacher that the literature review part of the social issues in fact part of the analysis and summary of each stage of the research part of this part of the paper will be carried on the next, and have a role as a Question.

## Final effect
### Front page
<img width="1200" alt="截屏2023-11-23 04 16 34" src="https://github.com/Jinaisrz/final_paper/assets/115119995/9454c26a-0728-4b9f-ae61-155826169075">

### Interest selection page
<img width="1197" alt="截屏2023-11-23 04 19 35" src="https://github.com/Jinaisrz/final_paper/assets/115119995/14b1642f-349a-4226-b345-a7785ea818a8">

### Handshake interface

![65c7d81fd5ebeda866e1ce160c014eee](https://github.com/Jinaisrz/final_paper/assets/115119995/9c1f3975-565f-4e58-abe5-30d0e094586c)

![912430371bb61aa98480d3c47550bff7](https://github.com/Jinaisrz/final_paper/assets/115119995/f935fbde-6a6c-41dc-859c-84a4e60825d7)


<img width="1599" alt="f2dae46df5613a7a03ab4cfb0b6d0aac" src="https://github.com/Jinaisrz/final_paper/assets/115119995/09fd1f84-cc04-465c-9c7a-a1e578c9f6cc">

![70f5ff397e9557c2094dc526f456d9c1](https://github.com/Jinaisrz/final_paper/assets/115119995/e6df900d-c32e-4b66-b4cb-868200aa5267)

<img width="848" alt="截屏2023-11-23 02 25 18" src="https://github.com/Jinaisrz/final_paper/assets/115119995/2096429a-8fb5-4336-9463-c75d6c23d786">

### Two-hand multiple-choice question interface

![a612c5e11b205e784fb949912a7b3a1b](https://github.com/Jinaisrz/final_paper/assets/115119995/421600a1-1fee-4589-92f0-cdaee4cffff8)

![4c25bd29da227f22ae2fd28121e07883](https://github.com/Jinaisrz/final_paper/assets/115119995/d7484e55-9069-46eb-974c-85a304a855db)

